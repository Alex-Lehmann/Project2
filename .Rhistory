c("EFM",""),
c("EFMS",""),
c("FORD program","TBS program for the development of Financial Officers FIs"),
c("FORD","TBS program for the development of Financial Officers FIs"),
c("DoF",""), #department of finance
c("FAB's",""),
c("FAMF",""),
c("FandA",""),
c("FMASD's","Financial Management & Advisory Services Directorate's"),
c("FMASD","Financial Management & Advisory Services Directorate"),
c("FMAs",""),
c("FMAS",""),
c("FMA's",""),
c("FRAD's",""),
c("FRAD",""),
c("FTEs",""),
c("GCWCC",""),
c("NPSW",""),
c("GLs",""),
c("GS's",""),
c("HRB",""),
c("IAFCD",""),
c("IBC",""),
c("IBC's",""),
c("ZDFA_RPT",""),
c("ID's",""), #alert
c("ISD",""), #alert
c("ITB",""),
c("ITSSP",""),
c("ITSS",""),
c("JVs",""),
c("KRP's",""),
c("MG1",""),
c("MG1's",""),
c("MG2",""),
c("MG2's",""),
c("MG3",""),
c("MG4",""),
c("MIFI",""),
c("ML3",""),
c("MyAccount",""),
c("NFDC",""),
c("NPSW",""),
c("OAG",""),
c("OGD",""),
c("OGDs",""),
c("OGD's",""),
c("P6",""),
c("P7",""),
c("PAB",""), #alert
c("PBF",""),
c("PC's",""),
c("PCCE",""),
c("PMBOK",""),
c("PMI",""),
c("PMP",""),
c("PRINCE2",""),
c("PO's",""),
c("PPSL",""),
c("PSSDSG",""),
c("PSPC",""),
c("RARAD",""),
c("RBA",""), #Alert
c("RC02",""),
c("client reorgs",""),
c("RR","respendable revenue"),
c("RMD","Resource Management Directorate"),
c("RP1","Tenant Request for work"),
c("RPA",""), #Alert
c("RPRD's",""),
c("RPSID","Real Property & Service Integration Directorate"),
c("RSCAD",""),
c("SIR's",""),
c("SIAD","Security and Internal Affairs Directorate"),
c("SP 02",""),
c("SP02",""),
c("SP2",""),
c("SP05",""),
c("SP5",""),
c("SP5s",""),
c("SP07",""),
c("SP3",""),
c("TETSO",""),
c("TNTSO",""),
c("TSO's",""),
c("TSOS",""),
c("TWTSO","west?"),
c("WFH",""),
c("","")
)
trueWords
trueWords <- rbind(
c("RARAD",""),
c("ITB",""),
c("ABSB",""),
c("CVB",""),
c("RMC",""),
c("CAS",""),
c("RC02",""),
c("ABSC",""),
c("AEP",""),
c("P3",""),
c("ATIPs",""),
c("ALASD",""),
c("EBus",""),
c("GCSurplus",""),
c("RP",""),
c("BGIS",""),
c("PSPC",""),
c("TETSO",""),
c("BECC",""),
c("BIQA",""),
c("CPB's",""),
c("BMC",""),
c("DMC",""),
c("DGs",""),
c("RMC bootcamps",""),
c("CERB",""),
c("CESB",""),
c("TBS",""),
c("FIs",""), #alert
c("CPIs",""),
c("CPSP",""),
c("CSMD",""),
c("DSFA","Delegation of Spending and Financial Authority"),
c("DTA",""),
c("EAP",""), #Careful as  appears in many words
c("ECOTSO",""),
c("EEs",""), #Careful as EEs
c("EFM",""),
c("EFMS",""),
c("FORD program","TBS program for the development of Financial Officers FIs"),
c("FORD","TBS program for the development of Financial Officers FIs"),
c("DoF",""), #department of finance
c("FAB's",""),
c("FAMF",""),
c("FandA",""),
c("FMASD's","Financial Management & Advisory Services Directorate's"),
c("FMASD","Financial Management & Advisory Services Directorate"),
c("FMAs",""),
c("FMAS",""),
c("FMA's",""),
c("FRAD's",""),
c("FRAD",""),
c("FTEs",""),
c("GCWCC",""),
c("NPSW",""),
c("GLs",""),
c("GS's",""),
c("HRB",""),
c("IAFCD",""),
c("IBC",""),
c("IBC's",""),
c("ZDFA_RPT",""),
c("ID's",""), #alert
c("ISD",""), #alert
c("ITB",""),
c("ITSSP",""),
c("ITSS",""),
c("JVs",""),
c("KRP's",""),
c("MG1",""),
c("MG1's",""),
c("MG2",""),
c("MG2's",""),
c("MG3",""),
c("MG4",""),
c("MIFI",""),
c("ML3",""),
c("MyAccount",""),
c("NFDC",""),
c("NPSW",""),
c("OAG",""),
c("OGD",""),
c("OGDs",""),
c("OGD's",""),
c("P6",""),
c("P7",""),
c("PAB",""), #alert
c("PBF",""),
c("PC's",""),
c("PCCE",""),
c("PMBOK",""),
c("PMI",""),
c("PMP",""),
c("PRINCE2",""),
c("PO's",""),
c("PPSL",""),
c("PSSDSG",""),
c("PSPC",""),
c("RARAD",""),
c("RBA",""), #Alert
c("RC02",""),
c("client reorgs",""),
c("RR","respendable revenue"),
c("RMD","Resource Management Directorate"),
c("RP1","Tenant Request for work"),
c("RPA",""), #Alert
c("RPRD's",""),
c("RPSID","Real Property & Service Integration Directorate"),
c("RSCAD",""),
c("SIR's",""),
c("SIAD","Security and Internal Affairs Directorate"),
c("SP 02",""),
c("SP02",""),
c("SP2",""),
c("SP05",""),
c("SP5",""),
c("SP5s",""),
c("SP07",""),
c("SP3",""),
c("TETSO",""),
c("TNTSO",""),
c("TSO's",""),
c("TSOS",""),
c("TWTSO","west?"),
c("WFH",""),
c("","")
)
trueWords
wordsForElimination <- rbind(
c("\\bbuilding\'s\\b",""),
c("\\bhttps://\\b",""),
c("\\b\\(IAR\\)\\b","")
)
wordsForElimination
g <- "https://www.google.com"
g <- "https://www.google.com"
str_replace_all(g,"\\bhttps://","gg")
g <- "hey you https://www.google.com"
str_replace_all(g,"\\bhttps://","gg")
orderedNonWords
forTranslation
gl_auth("/Users/johnbrooks/Dropbox/Synced/Credentials/API/STAT 5702 - Text Translation-df0390ca10f9.json")
?gl_translate()
counterChar
forTranslation$response == ""
translationFeed <- forTranslation$response[forTranslation$response == ""]
translationFeed
translationFeed <- forTranslation$response[!(forTranslation$response == "")]
translationFeed
View(translationFeed)
?(gl_translate)
?gl_translate())
?gl_translate()
t_string <- translationFeed[1]
t_string
translationEnFr <- gl_translate(
t_string,
target = "en",
format = "text",
source = "fr",
model = "nmt"
)
translationEnFr
View(translationEnFr$translatedText)
translationEnFrB <- gl_translate(
t_string,
target = "en",
format = "text",
source = "fr",
model = "base"
)
View(translationEnFrB)
rbind(
translationEnFr,
translationEnFrB
)
translationFrame <- data.frame()
translationFeed
nrow(translationFeed)
length(translationFeed)
translationFrame <- translationEnFr
translationFrame
View(translationFeed)
c(2:7,9:length(translationFeed))
translationFrame
for (i in 2:length(translationFeed)){
if(i!=8){
translationEnFr <- gl_translate(
translationFeed[i],
target = "en",
format = "text",
source = "fr",
model = "nmt"
)
}
translationFrame <- rbind(translationFrame, translationEnFr)
}
getwd()
?saveRDS()
saveRDS(translationFrame,"frenchToEnglish.rds")
g <- readRDS("frenchToEnglish.rds")
g
write.xlsx(g, "frenchToEnglish.xlsx")
View(cleanData)
# Extra
d <- "off toff staffed on the cuff ff (fford's), AoS AA"
str_replace_all(d,"\\<[[:upper:]]*[[:upper:]]*\\>","")
library(xlsx)
library(tidyr)
library(tidytext)
library(tidyverse)
library(dplyr)
library(stringr)
str_replace_all(d,"\\<[[:upper:]]*[[:upper:]]*\\>","")
str_replace_all(d,"\\<[[:upper:]][[:upper:]]\\>","")
str_replace_all(d,"\\b[[:upper:]][[:upper:]]\\b","")
str_replace_all(d,"\\b[[:upper:]].[[:upper:]].\\b","")
initialismPattern <- c(
"\\b[[:upper:]]\\w[[:upper:]].\\b"
)
str_replace_all(d,initialismPattern,"")
initialismPattern <- c(
"\\b[[:upper:]]\\w[[:upper:]]\\w\\b",
"\\b[[:upper:]][[:upper:]]\\w\\b",
"\\b[[:upper:]][[:upper:]]\\b"
)
initialismPattern
# Initialize libraries
## Standard
library(xlsx)
library(tidyr)
library(tidytext)
library(tidyverse)
library(dplyr)
library(stringr)
## Words list that includes variations of words (e.g. searched, searching, etc. for search)
# install.packages("qdapDictionaries")
library(qdapDictionaries)
## Translation
# install.packages("googleLanguageR")
library(googleLanguageR)
# Load authorization
gl_auth("/Users/johnbrooks/Dropbox/Synced/Credentials/API/STAT 5702 - Text Translation-df0390ca10f9.json")
# https://cran.r-project.org/web/packages/googleLanguageR/vignettes/setup.html
# Read in file
dirIn <- "/Users/johnbrooks/Desktop/Course Work/STAT5702/Project2"
fileIn <- "Redacted FAB_Project_raw_data_Clean EXCEL Dec.23"
# Create Path
pathIn <- paste(dirIn,"/",fileIn,".xlsx",sep="")
# Read in data
rawData <- read.xlsx(pathIn,1)
# Process columns
columnNamesStore <- names(rawData)
cleanData <- rawData
names(cleanData) <- paste("c",1:ncol(cleanData),sep="_")
View(cleanData)
nonCatColumns <- c(14,
22,
30,
40,
41,
43,
45,
46,
48)
# Scrape free text columns
procData <- cleanData[,c(1,2,nonCatColumns)]
newNames <- names(procData)
selectNames  <- newNames[c(3:length(newNames))]
######### Translate here
# Pivot the data
pivtData <- procData %>%
# Select only those columns with the ID and the phrases
select(c("c_1","c_2",selectNames)) %>%
# Pivot the data to be cataloged by ID and question index
pivot_longer(selectNames,names_to = "column",values_to = "response")
# Prepare data for translation
forTranslation <- pivtData %>%
# Take out french
filter(c_2 == "FR")
# Count Characters
counterChar <- 0
for(currentStr in forTranslation$response) {
counterChar <- counterChar + str_length(currentStr)
}
# Translational functional block
## Commented out as running it too many time could mean $$$
## control + shift + C to activate / deactivate lines
# translationFeed <- forTranslation$response[!(forTranslation$response == "")]
#
# translationFrame <- gl_translate(
#   t_string,
#   target = "en",
#   format = "text",
#   source = "fr",
#   model = "nmt"
# )
#
# for (i in 2:length(translationFeed)){
#   if(i!=8){
#     translationEnFr <- gl_translate(
#       translationFeed[i],
#       target = "en",
#       format = "text",
#       source = "fr",
#       model = "nmt"
#     )
#   }
#   translationFrame <- rbind(translationFrame, translationEnFr)
# }
#
# saveRDS(translationFrame,"frenchToEnglish.rds")
# How to read / write the file
# g <- readRDS("frenchToEnglish.rds")
# write.xlsx(g, "frenchToEnglish.xlsx")
# Prepare data for assessment
forProcessEng <- pivtData %>%
# Take out french
filter(c_2 == "EN") %>%
# Get the responses into words
unnest_tokens(word, response) %>%
# Select the words column
select(c("word")) %>%
# Get the unique words
unique()
grepl(forProcessEng,initialismPattern)
forProcessEng
View(pivtData)
grep(pivtData$response,initialismPattern)
str_extract_all(pivtData$response,initialismPattern)
str_extract_all(pivtData$response,initialismPattern[1])
responsesTogether <- paste(pivtData$response, collapse = "\n")
View(responsesTogether)
responsesTogether
str_extract_all(responsesTogether,initialismPattern[1])
str_extract_all(responsesTogether,initialismPattern)
listInitialisms <- unlist(str_extract_all(responsesTogether,initialismPattern))
listInitialisms
listInitialisms <- unlist(str_extract_all(responsesTogether,initialismPattern)) %>%
unique()
listInitialisms
initialismPattern
# Create patterns to find initialisms
initialismPattern <- c(
"\\b\\w[[:upper:]]\\w[[:upper:]]\\w\\b",
"\\b[[:upper:]]\\w[[:upper:]]\\w\\b",
"\\b\\w[[:upper:]]\\w[[:upper:]]\\b",
"\\b\\w[[:upper:]][[:upper:]]\\w\\b",
"\\b[[:upper:]][[:upper:]]\\w\\b",
"\\b\\w[[:upper:]][[:upper:]]\\b",
"\\b[[:upper:]]\\w[[:upper:]]\\b",
"\\b[[:upper:]][[:upper:]]\\b"
)
responsesTogether <- paste(pivtData$response, collapse = "\n")
listInitialisms <- unlist(str_extract_all(responsesTogether,initialismPattern)) %>%
unique()
listInitialisms
# Create patterns to find initialisms
initialismPattern <- c(
"\\b\\w+[[:upper:]]\\w+[[:upper:]]\\w+\\b",
"\\b[[:upper:]]\\w+[[:upper:]]\\w+\\b",
"\\b\\w+[[:upper:]]\\w+[[:upper:]]\\b",
"\\b\\w+[[:upper:]][[:upper:]]\\w+\\b",
"\\b[[:upper:]][[:upper:]]\\w+\\b",
"\\b\\w+[[:upper:]][[:upper:]]\\b",
"\\b[[:upper:]]\\w+[[:upper:]]\\b",
"\\b[[:upper:]][[:upper:]]\\b"
)
listInitialisms <- unlist(str_extract_all(responsesTogether,initialismPattern)) %>%
unique()
listInitialisms
# Create patterns to find initialisms
initialismPattern <- c(
# Natural strings
"\\b\\w+[[:upper:]]\\w+[[:upper:]]\\w+\\b",
"\\b[[:upper:]]\\w+[[:upper:]]\\w+\\b",
"\\b\\w+[[:upper:]]\\w+[[:upper:]]\\b",
"\\b\\w+[[:upper:]][[:upper:]]\\w+\\b",
"\\b[[:upper:]][[:upper:]]\\w+\\b",
"\\b\\w+[[:upper:]][[:upper:]]\\b",
"\\b[[:upper:]]\\w+[[:upper:]]\\b",
"\\b[[:upper:]][[:upper:]]\\b",
# Possessive strings
"\\b\\w+[[:upper:]]\\w+[[:upper:]]\\w+\'s\\b",
"\\b[[:upper:]]\\w+[[:upper:]]\\w+\'s\\b",
"\\b\\w+[[:upper:]]\\w+[[:upper:]]\'s\\b",
"\\b\\w+[[:upper:]][[:upper:]]\\w+\'s\\b",
"\\b[[:upper:]][[:upper:]]\\w+\'s\\b",
"\\b\\w+[[:upper:]][[:upper:]]\'s\\b",
"\\b[[:upper:]]\\w+[[:upper:]]\'s\\b",
"\\b[[:upper:]][[:upper:]]\'s\\b"
)
listInitialisms <- unlist(str_extract_all(responsesTogether,initialismPattern)) %>%
unique()
listInitialisms
sort(listInitialisms)
listInitialisms <- unlist(str_extract_all(responsesTogether,initialismPattern)) %>%
unique() %>%
sort()
listInitialisms
?grep()
# For each initialism find where it was discovered
grep(listInitialisms[1],pivtData$response)
Length(pivtData$response)
pivtData$response
length(pivtData$response)
# For each initialism find where it was discovered
indexHold <- c()
respondsHold <- c()
for(initialismIndex in 1:length(listInitialisms)){
currentResponses <- grep(listInitialisms[initialismIndex],pivtData$response)
respondsHold <- c(respondsHold, currentResponses)
indexHold <- c(indexHold, rep(initialismIndex,length(currentResponses)))
}
respondsHold
# Decode verifiction frame
verificationFrame <- data.frame(listInitialisms[indexHold],
pivtData$response[respondsHold])
# Write the verification fram to an excel file for ease of viewing
write.xlsx(verificationFrame,"initialsVerification.xlsx")
